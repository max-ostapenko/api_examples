{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMp+ArGhNnDNzAqMYu46HNv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/max-ostapenko/api_examples/blob/main/examples/python_notebook/bigquery_vector_search.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Configure environment and resources\n",
        "\n"
      ],
      "metadata": {
        "id": "UU5H-5FeW6eD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Authorise Google Colab with GCP access"
      ],
      "metadata": {
        "id": "oNvqBYvLmInt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a9MjY0kiQRyr",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "project_id = 'max-ostapenko' # @param {type: \"string\"}\n",
        "dataset_id = 'vector_search' # @param {type: \"string\"}\n",
        "location_id = 'us' # @param {type: \"string\"}\n",
        "\n",
        "# Create a dataset for vector search resources\n",
        "!bq mk --project_id={project_id} --location {location_id} --dataset {dataset_id}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Connect Vertex AI model via BigQuery connections"
      ],
      "metadata": {
        "id": "71OOGBW8mFBv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create BigQuery connection to Google cloud resources\n",
        "connection_id = \"vertex_ai-remote_functions-big_lake\"\n",
        "!bq mk --project_id={project_id} --location={location_id} \\\n",
        "    --connection_type=CLOUD_RESOURCE --connection {connection_id}\n",
        "\n",
        "# Extract service account ID from the connection details\n",
        "import subprocess, json\n",
        "connection_details = json.loads(\n",
        "    subprocess.check_output(\"bq show --project_id={project_id} --location={location_id} --format=json --connection {connection_id}\".format(\n",
        "        project_id=project_id,\n",
        "        location_id=location_id,\n",
        "        connection_id=connection_id\n",
        "        ).split(\" \")\n",
        "    ).decode('utf-8')\n",
        ")\n",
        "service_account = connection_details[\"cloudResource\"][\"serviceAccountId\"]\n",
        "\n",
        "# Authorise 'Vertex AI User' role for connection service account\n",
        "!gcloud projects add-iam-policy-binding {project_id} \\\n",
        "    --member='serviceAccount:{service_account}' --role='roles/aiplatform.user' > /dev/null\n",
        "\n",
        "# Create BQ ML model for multimodal embeddings\n",
        "create_model_query = \"\"\"\n",
        "CREATE OR REPLACE MODEL `{project_id}.{dataset_id}.multimodalembedding`\n",
        "REMOTE WITH CONNECTION `{project_id}.{location_id}.vertex_ai-remote_functions-big_lake`\n",
        "OPTIONS (ENDPOINT = \"textembedding-gecko@latest\");\n",
        "\"\"\".format(dataset_id=dataset_id, project_id=project_id, location_id=location_id)\n",
        "!bq query --project_id={project_id} --use_legacy_sql=false '{create_model_query}'"
      ],
      "metadata": {
        "id": "hjaR39aCQ-ql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate embeddings table\n",
        "\n",
        "[ML.GENERATE_TEXT_EMBEDDING function](https://cloud.google.com/bigquery/docs/reference/standard-sql/bigqueryml-syntax-generate-text-embedding) converts strings to a vector within semantic space.\n",
        "\n",
        "[Cost of multimodal embeddings generation via Vertex AI endpoint](https://cloud.google.com/vertex-ai/pricing#image_generation)."
      ],
      "metadata": {
        "id": "KQqgQDBsTiA-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate embeddings from URLs list"
      ],
      "metadata": {
        "id": "aV4_ynywmQt8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title { vertical-output: true }\n",
        "get_product_names_query = \"\"\"\n",
        "CREATE OR REPLACE TABLE\n",
        "    `{dataset_id}.url_embedded` AS (\n",
        "    SELECT\n",
        "        *\n",
        "    FROM\n",
        "        ML.GENERATE_TEXT_EMBEDDING( MODEL `{dataset_id}.multimodalembedding`,\n",
        "            (\n",
        "            SELECT\n",
        "                url AS content\n",
        "            FROM `httparchive.urls.latest_crux_desktop`\n",
        "            WHERE rank = 1000\n",
        "            LIMIT 1000 ),\n",
        "            STRUCT(TRUE AS flatten_json_output) ) );\n",
        "\"\"\".format(dataset_id=dataset_id)\n",
        "!bq query --project_id={project_id} --use_legacy_sql=false '{get_product_names_query}'\n",
        "\n",
        "# Preview the table\n",
        "query_product_names = \"\"\"\n",
        "SELECT\n",
        "    content, statistics, ml_embed_text_status, text_embedding\n",
        "FROM\n",
        "`{dataset_id}.url_embedded`\n",
        "LIMIT 5\n",
        "\"\"\".format(dataset_id=dataset_id)\n",
        "!bq query --project_id={project_id} --use_legacy_sql=false '{query_product_names}'"
      ],
      "metadata": {
        "id": "zNiNg0O9Q69I",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate embeddings from IMDB catalogue"
      ],
      "metadata": {
        "id": "MARVWOD5mUzq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title { vertical-output: true }\n",
        "get_product_names_query = \"\"\"\n",
        "CREATE OR REPLACE TABLE\n",
        "    `{dataset_id}.movie_title_embedded` AS (\n",
        "    SELECT\n",
        "        *\n",
        "    FROM\n",
        "        ML.GENERATE_TEXT_EMBEDDING( MODEL `{dataset_id}.multimodalembedding`,\n",
        "            (\n",
        "                SELECT\n",
        "                    primary_title as content\n",
        "                FROM `bigquery-public-data.imdb.title_basics`\n",
        "                WHERE\n",
        "                    title_type = \"movie\"\n",
        "                    AND start_year > 1970\n",
        "                    AND is_adult = 0\n",
        "                    AND tconst IN (\n",
        "                        SELECT\n",
        "                            tconst\n",
        "                        FROM `bigquery-public-data.imdb.title_ratings`\n",
        "                        WHERE\n",
        "                            average_rating > 6.5\n",
        "                            AND num_votes > 10000\n",
        "                    )\n",
        "                ),\n",
        "            STRUCT(TRUE AS flatten_json_output) ) );\n",
        "\"\"\".format(dataset_id=dataset_id)\n",
        "!bq query --project_id={project_id} --use_legacy_sql=false '{get_product_names_query}'\n",
        "\n",
        "# Preview the table\n",
        "query_product_names = \"\"\"\n",
        "SELECT\n",
        "    content, statistics, ml_embed_text_status, text_embedding\n",
        "FROM\n",
        "`{dataset_id}.movie_title_embedded`\n",
        "LIMIT 5\n",
        "\"\"\".format(dataset_id=dataset_id)\n",
        "!bq query --project_id={project_id} --use_legacy_sql=false '{query_product_names}'"
      ],
      "metadata": {
        "cellView": "form",
        "id": "VPTxxbBwTupb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Search for neighbours\n",
        "\n",
        "The search cost consists of:\n",
        "- cost of an embedding generation for a search query (can be ignored for short queries),\n",
        "- cost of BigQuery processing."
      ],
      "metadata": {
        "id": "tlFNoSI1Tlf-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Websites classification"
      ],
      "metadata": {
        "id": "cRTecvXTmk9Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "search_query = \"Social\" # @param {type: \"string\"}\n",
        "top_k = \"10\" # @param {type: \"string\"}\n",
        "\n",
        "select_neighbours_query = \"\"\"\n",
        "SELECT\n",
        "    base.content AS base_content,\n",
        "    distance\n",
        "FROM\n",
        "    VECTOR_SEARCH( TABLE {dataset_id}.url_embedded,\n",
        "        \"text_embedding\",\n",
        "        (\n",
        "        SELECT\n",
        "            content,\n",
        "            text_embedding\n",
        "        FROM\n",
        "            ML.GENERATE_TEXT_EMBEDDING( MODEL `{dataset_id}.multimodalembedding`,\n",
        "                (\n",
        "                SELECT\n",
        "                    \"{search_query}\" AS content),\n",
        "                STRUCT(TRUE AS flatten_json_output) ) ),\n",
        "        \"text_embedding\",\n",
        "        top_k => {top_k} );\n",
        "\"\"\".format(\n",
        "    dataset_id=dataset_id,\n",
        "    search_query=search_query,\n",
        "    top_k = top_k\n",
        ")\n",
        "\n",
        "!bq query --project_id={project_id} --use_legacy_sql=false '{select_neighbours_query}'"
      ],
      "metadata": {
        "id": "6j8t1hwIRClX",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Movie title recommendation"
      ],
      "metadata": {
        "id": "5YePQQ0omo9j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "search_query = \"Francis Ford Coppola\" # @param {type: \"string\"}\n",
        "top_k = \"10\" # @param {type: \"string\"}\n",
        "\n",
        "select_neighbours_query = \"\"\"\n",
        "SELECT\n",
        "    base.content AS base_content,\n",
        "    distance\n",
        "FROM\n",
        "    VECTOR_SEARCH( TABLE {dataset_id}.movie_title_embedded,\n",
        "        \"text_embedding\",\n",
        "        (\n",
        "        SELECT\n",
        "            content,\n",
        "            text_embedding\n",
        "        FROM\n",
        "            ML.GENERATE_TEXT_EMBEDDING( MODEL `{dataset_id}.multimodalembedding`,\n",
        "                (\n",
        "                SELECT\n",
        "                    \"{search_query}\" AS content),\n",
        "                STRUCT(TRUE AS flatten_json_output) ) ),\n",
        "        \"text_embedding\",\n",
        "        top_k => {top_k} );\n",
        "\"\"\".format(\n",
        "    dataset_id=dataset_id,\n",
        "    search_query=search_query,\n",
        "    top_k = top_k\n",
        ")\n",
        "\n",
        "!bq query --project_id={project_id} --use_legacy_sql=false '{select_neighbours_query}'"
      ],
      "metadata": {
        "cellView": "form",
        "id": "MGh8MRheT_xl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}